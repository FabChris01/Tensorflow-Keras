Tensorflow and Keras Learning Challenge Day 37
===============================================

# Sources:
- https://www.tensorflow.org/tutorials/text/solve_glue_tasks_using_bert_on_tpu
- https://www.tensorflow.org/guide/gpu

# Learning Updates:
- The simplest way to run on multiple GPUs, on one or many machines, is using Distribution Strategies.
- TensorFlow supports running computations on a variety of types of devices, including CPU and GPU. 
- They are represented with string identifiers for example:
1) "/device:CPU:0": The CPU of your machine.
2) "/GPU:0": Short-hand notation for the first GPU of your machine that is visible to TensorFlow.
3) "/job:localhost/replica:0/task:0/device:GPU:1": Fully qualified name of the second GPU of your machine that is visible to TensorFlow.
- BERT can also be used to solve many problems in natural language processing.


# Looking forward to Learning more!